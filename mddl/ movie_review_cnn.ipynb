{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692a8e4c-39de-4527-8a20-d58508d3bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979d4bce-4c10-4716-a977-db51195dfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_' + string], '')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_' + string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9931e71e-e2fc-4ca1-ac9d-1c3342b64abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data/movie/data-in/'\n",
    "DATA_OUT_PATH = './data/movie/data-out/'\n",
    "INPUT_TRAIN_DATA = 'nsmc_train_input.npy'\n",
    "LABEL_TRAIN_DATA = 'nsmc_train_label.npy'\n",
    "DATA_CONFIGS = 'nsmc_data_configs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920674fd-3347-48e1-b0c4-233f1fd742da",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0433de-043c-4d38-9de6-ecb04388ad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = np.load(open(DATA_IN_PATH + INPUT_TRAIN_DATA, 'rb'))\n",
    "train_label = np.load(open(DATA_IN_PATH + LABEL_TRAIN_DATA, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b9a8f3-cffd-4f48-9847-76673b1dfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn_classifier_kr'\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 10\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "        'vocab_size': prepro_configs['vocab_size'],\n",
    "        'embedding_size': 128,\n",
    "        'num_filters': 100,\n",
    "        'dropout_rate': 0.5,\n",
    "        'hidden_dimension': 250,\n",
    "        'output_dimension':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc3c677-e67e-41ef-952e-cbc2a9275a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, **kargs):\n",
    "        super(CNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "        self.embedding = layers.Embedding(input_dim=kargs['vocab_size']+1,\n",
    "                                     output_dim=kargs['embedding_size'])\n",
    "        self.conv_list = [layers.Conv1D(filters=kargs['num_filters'],\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   padding='valid',\n",
    "                                   activation='relu',\n",
    "                                   kernel_constraint=tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "                                      #MaxNorm(max_value=3.) 커널의 가중치값이 최대 값 3을 넘지 않게 설정\n",
    "                         for kernel_size in [3,4,5]]\n",
    "        self.pooling = layers.GlobalMaxPooling1D()\n",
    "        self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
    "        self.fc1 = layers.Dense(units=kargs['hidden_dimension'],\n",
    "                           activation='relu',\n",
    "                           kernel_constraint=tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "        self.fc2 = layers.Dense(units=kargs['output_dimension'],\n",
    "                           activation='sigmoid',\n",
    "                           kernel_constraint=tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = tf.concat([self.pooling(conv(x)) for conv in self.conv_list], axis=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07711862-1d18-4cbf-9170-c877b293f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier(**kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7944f67f-ef7d-4b7a-86c3-66a50a029b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((BATCH_SIZE, MAX_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62be13c-a1ab-4634-ad53-070049b9c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_classifier_kr\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  5600896   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             multiple                  38500     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           multiple                  51300     \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           multiple                  64100     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  multiple                 0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  75250     \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,830,297\n",
      "Trainable params: 5,830,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5a31ff-5084-4a2a-acf5-fe6e309d74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c5f928-a646-489e-8c5e-eee6a58232bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuray', min_delta=0.0001, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c4107b-7dd6-415c-917d-d124d9029615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/movie/data-out/cnn_classifier_kr -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True\n",
    "    , save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7e9527-f52a-4c61-9730-55ad412aafea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.4568 - accuracy: 0.7779WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82000, saving model to ./data/movie/data-out/cnn_classifier_kr\\weights.h5\n",
      "264/264 [==============================] - 14s 49ms/step - loss: 0.4566 - accuracy: 0.7780 - val_loss: 0.3971 - val_accuracy: 0.8200\n",
      "Epoch 2/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.3521 - accuracy: 0.8447WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.82000 to 0.82687, saving model to ./data/movie/data-out/cnn_classifier_kr\\weights.h5\n",
      "264/264 [==============================] - 13s 49ms/step - loss: 0.3520 - accuracy: 0.8447 - val_loss: 0.3829 - val_accuracy: 0.8269\n",
      "Epoch 3/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.3007 - accuracy: 0.8727WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 13s 49ms/step - loss: 0.3008 - accuracy: 0.8726 - val_loss: 0.3939 - val_accuracy: 0.8248\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.8941WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 13s 48ms/step - loss: 0.2560 - accuracy: 0.8941 - val_loss: 0.4218 - val_accuracy: 0.8196\n",
      "Epoch 5/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9098WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 13s 49ms/step - loss: 0.2215 - accuracy: 0.9098 - val_loss: 0.4385 - val_accuracy: 0.8217\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 0.9209WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 12s 47ms/step - loss: 0.1943 - accuracy: 0.9209 - val_loss: 0.4546 - val_accuracy: 0.8206\n",
      "Epoch 7/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9297WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 13s 49ms/step - loss: 0.1733 - accuracy: 0.9296 - val_loss: 0.4941 - val_accuracy: 0.8212\n",
      "Epoch 8/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9349WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 13s 51ms/step - loss: 0.1589 - accuracy: 0.9349 - val_loss: 0.4993 - val_accuracy: 0.8224\n",
      "Epoch 9/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 0.9402WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 13s 50ms/step - loss: 0.1474 - accuracy: 0.9402 - val_loss: 0.5383 - val_accuracy: 0.8205\n",
      "Epoch 10/10\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9447WARNING:tensorflow:Early stopping conditioned on metric `val_accuray` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.82687\n",
      "264/264 [==============================] - 13s 49ms/step - loss: 0.1359 - accuracy: 0.9447 - val_loss: 0.5569 - val_accuracy: 0.8167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input, train_label, batch_size=BATCH_SIZE\n",
    "                    , epochs=NUM_EPOCHS, validation_split=VALID_SPLIT\n",
    "                    , callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249e62f-7a61-42bc-a626-085cbe808d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97518ee6-57f8-4644-ac3f-69d0d7889f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data/movie/data-out/'\n",
    "INPUT_TEST_DATA = 'nsmc_test_input.npy'\n",
    "LABEL_TEST_DATA = 'nsmc_test_label.npy'\n",
    "SAVE_FILE_NM = 'weights.h5'\n",
    "\n",
    "test_input = np.load(open(DATA_IN_PATH + INPUT_TEST_DATA, 'rb'))\n",
    "test_label_data = np.load(open(DATA_IN_PATH + LABEL_TEST_DATA, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "722bee83-cd8b-4800-9a51-23910474d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_NM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cca8a7f-6c5e-45a2-bd31-117eef843fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3856 - accuracy: 0.8264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38564741611480713, 0.8264399766921997]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input, test_label_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
